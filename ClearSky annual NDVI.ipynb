{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4767fd9d-2074-4e03-81ef-1b4fa8f7fcc5",
   "metadata": {},
   "source": [
    "# Creating annual vegetation curves to correlate with ground-based surveys\n",
    "\n",
    "This code processes geospatial data to analyze and visualize the clear sky conditions, NDVI, and LAI indices for specified sites over different years. It uses a shapefile to define the study areas and Earth Engine to retrieve satellite imagery. For each site and year, the code calculates clear sky percentages, NDVI, LAI, and aerosol optical thickness (AOT). It identifies the closest dates to the end of specified survey periods with varying levels of clear sky coverage and saves these dates in a CSV file. The code also generates scatter plots of NDVI and LAI indices, highlighting the closest date with over 99% clear sky pixels in yellow, and saves these plots in the working directory. This comprehensive analysis helps in understanding the vegetation dynamics and atmospheric conditions during the survey periods.\n",
    "\n",
    "Follow-up code to this will provide functionalitly to download the \"closest clear-sky\" image for each site for processing in SNAP, or with success, automatically download and process that imagery using SNAP algorithms via snappy or satellitetools packages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a934a-7d16-49bf-8e98-c767b1b72129",
   "metadata": {},
   "source": [
    "Load required packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6908e-80d4-4f76-b397-61cfcbb73c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f7f4c-9c63-4e90-b9eb-2b0552302ad3",
   "metadata": {},
   "source": [
    "Authenticate and initialize google earth engine - you will need an account. If it is your first time linking to your account, a new window will open and take you through the process. If this does not work, try ee.Authenticate(force=True). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef1802-f504-4dfe-9d09-78ade977f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Earth Engine module.\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd9d23c-92b6-4382-8536-11a1b501411e",
   "metadata": {},
   "source": [
    "Load a shapefile, convert its coordinates to WGS84 projection, extract polygon geometries, and ensure they are valid for use with Google Earth Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f22c60-5f7d-4f06-b0a3-a16e72ff192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "shapefile_path = r'C:\\Your shapefile.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf.to_crs(epsg=4326)  # Convert to WGS84 projection\n",
    "geojson = gdf.__geo_interface__\n",
    "site_names = gdf['Site'].tolist() #Change this to correspond to your polygon id \n",
    "\n",
    "# Convert GeoJSON to EE geometries and ensure valid polygons\n",
    "polygons = []\n",
    "for feature in geojson['features']:\n",
    "    if feature['geometry']['type'] == 'Polygon':\n",
    "        for coords in feature['geometry']['coordinates']:\n",
    "            if len(coords) >= 3:  # Ensure there are at least 3 points\n",
    "                polygons.append(ee.Geometry.Polygon(coords))\n",
    "    elif feature['geometry']['type'] == 'MultiPolygon':\n",
    "        for polygon in feature['geometry']['coordinates']:\n",
    "            for coords in polygon:\n",
    "                if len(coords) >= 3:  # Ensure there are at least 3 points\n",
    "                    polygons.append(ee.Geometry.Polygon(coords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38382358-975c-4599-abc4-cd52d375d6d3",
   "metadata": {},
   "source": [
    "Enter survey dates or date ranges and convert to pandas datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193f294-c3d7-49dd-8cd9-9e8dff3862b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define survey date ranges for each year\n",
    "survey_ranges = {\n",
    "    2019: ('2019-07-26', '2019-07-27'),\n",
    "    2020: ('2020-07-06', '2020-07-09'),\n",
    "    2021: ('2021-07-10', '2021-07-12'),\n",
    "    2022: ('2022-07-01', '2022-07-02'),\n",
    "    2023: ('2023-07-24', '2023-07-30'),\n",
    "}\n",
    "\n",
    "# Convert survey ranges to pandas datetime format\n",
    "for year in survey_ranges:\n",
    "    survey_ranges[year] = (pd.to_datetime(survey_ranges[year][0]), pd.to_datetime(survey_ranges[year][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935a144-c800-4c9c-9e19-18457d3cc13a",
   "metadata": {},
   "source": [
    "The s2_clear_sky function applies a mask to satellite imagery to retain only the pixels classified as clear sky using the SCL band, following the s2ClearSky method. \n",
    "\n",
    "The calculate_clear_sky_percentage function then calculates the percentage of clear sky pixels within a specified geometry by comparing the count of clear sky pixels to the total number of pixels in the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292d3f3-e663-47a0-a3f8-f4b57aa7338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud masking function using the SCL band following the s2ClearSky method\n",
    "def s2_clear_sky(image):\n",
    "    scl = image.select('SCL')\n",
    "    clear_sky_pixels = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(11)) #This means that only veg (4) bare soil (5) water (6) and snow (11) pixels are considered \"clear sky\" \n",
    "    return image.updateMask(clear_sky_pixels) \n",
    "\n",
    "# Function to calculate clear sky percentage using the SCL band\n",
    "def calculate_clear_sky_percentage(image, geometry):\n",
    "    total_pixels = image.reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        geometry=geometry,\n",
    "        scale=30,  # Use larger scale to reduce computation decrease to 10 for reporting on small <10ha areas\n",
    "        bestEffort=True\n",
    "    ).values().get(0)\n",
    "    \n",
    "    clear_sky_pixels = s2_clear_sky(image).reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        geometry=geometry,\n",
    "        scale=30,  # Use larger scale to reduce computation decrease to 10 for reporting on small <10ha areas\n",
    "        bestEffort=True\n",
    "    ).values().get(0)\n",
    "    \n",
    "    clear_sky_percentage = ee.Number(clear_sky_pixels).divide(total_pixels).multiply(100)\n",
    "    return clear_sky_percentage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978fea8-d73f-46a2-83b6-41cecb895729",
   "metadata": {},
   "source": [
    "\n",
    "This code processes geospatial data to analyze clear sky conditions, NDVI, LAI, and AOT indices for specified sites over different years, generating plots and saving results for further analysis.\n",
    "- NDVI (Normalized Difference Vegetation Index): NDVI is a measure of vegetation health and density, calculated using the difference between near-infrared and red light reflected by vegetation.\n",
    "- LAI (Leaf Area Index): LAI quantifies the total leaf area of plants per unit ground area, indicating the density of plant foliage.\n",
    "- AOT (Aerosol Optical Thickness): AOT measures the extent to which aerosols prevent the transmission of sunlight through the atmosphere, indicating the concentration of particulate matter. If applicable, this can be used to filter images effected by wildfire smoke. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43860af6-c128-4bdf-9bca-46c3a4f0a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate AOT, NDVI, and LAI, filtering out non-clear sky pixels\n",
    "def calculate_indices(image, geometry):\n",
    "    # Apply clear sky mask\n",
    "    clear_sky_image = s2_clear_sky(image)\n",
    "    \n",
    "    # Calculate NDVI\n",
    "    ndvi = clear_sky_image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "    # Calculate LAI\n",
    "    lai = clear_sky_image.expression('3.618 * NDVI - 0.118', {'NDVI': ndvi}).rename('LAI') # The LAI VI is of questionable use - but the goal of this program is LAI, though we will use SNAP from the closest_date image\n",
    "    # Calculate AOT using Sentinel-5P\n",
    "    start_date = image.date().advance(-1, 'day')\n",
    "    end_date = image.date().advance(1, 'day')\n",
    "    aot = ee.ImageCollection('COPERNICUS/S5P/OFFL/L3_AER_AI') \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filterBounds(geometry) \\\n",
    "        .mean().select('absorbing_aerosol_index')\n",
    "    \n",
    "    # Reduce to region\n",
    "    ndvi_mean = ndvi.reduceRegion(reducer=ee.Reducer.mean(), geometry=geometry, scale=30, bestEffort=True).get('NDVI') # Use larger scale to reduce computation decrease to 10 for reporting on small <10ha areas\n",
    "    lai_mean = lai.reduceRegion(reducer=ee.Reducer.mean(), geometry=geometry, scale=30, bestEffort=True).get('LAI') # Use larger scale to reduce computation decrease to 10 for reporting on small <10ha areas\n",
    "    aot_mean = aot.reduceRegion(reducer=ee.Reducer.mean(), geometry=geometry, scale=1000, bestEffort=True).get('absorbing_aerosol_index') # this scale means it can't be used for a mask, only dropping returns \n",
    "\n",
    "    return ndvi_mean, lai_mean, aot_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1468261-efdf-4aa3-a150-d63d10b3fb74",
   "metadata": {},
   "source": [
    "This section processes geospatial data for each site and year to calculate clear sky percentages, NDVI, LAI, and AOT indices, and stores the results in data frames. It divides the year into batches to handle satellite imagery, computes relevant indices, and saves the data to CSV files. Additionally, it identifies and records the closest dates to the end of specified survey periods that meet varying clear sky thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4bcfd-3580-4e05-9dac-035f33c096f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get clear sky data for each year in batches\n",
    "def process_year_data(year, geometry, site_name):\n",
    "    start_date = f'{year}-04-01' # Change these dates depending on your growing season\n",
    "    end_date = f'{year}-10-31'\n",
    "    \n",
    "    def get_clear_sky_data(image):\n",
    "        date = image.date().format('YYYY-MM-dd')\n",
    "        clear_sky_percentage = calculate_clear_sky_percentage(image, geometry)\n",
    "        ndvi_mean, lai_mean, aot_mean = calculate_indices(image, geometry)\n",
    "        return ee.Feature(None, {\n",
    "            'date': date,\n",
    "            'clear_sky_percentage': clear_sky_percentage,\n",
    "            'ndvi': ndvi_mean,\n",
    "            'lai': lai_mean,\n",
    "            'aot': aot_mean\n",
    "        })\n",
    "\n",
    "    # Process in batches\n",
    "    date_ranges = [\n",
    "        (f'{year}-04-01', f'{year}-05-31'),\n",
    "        (f'{year}-06-01', f'{year}-07-31'),\n",
    "        (f'{year}-08-01', f'{year}-09-30'),\n",
    "        (f'{year}-10-01', f'{year}-10-31')\n",
    "    ]\n",
    "    \n",
    "    data = []\n",
    "    for start, end in date_ranges:\n",
    "        sentinel_collection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\") \\\n",
    "            .filterDate(start, end) \\\n",
    "            .filterBounds(geometry)\n",
    "        \n",
    "        clear_sky_data = sentinel_collection.map(get_clear_sky_data).getInfo()\n",
    "        \n",
    "        for feature in clear_sky_data['features']:\n",
    "            date = feature['properties']['date']\n",
    "            clear_sky_percentage = feature['properties']['clear_sky_percentage']\n",
    "            ndvi = feature['properties']['ndvi']\n",
    "            lai = feature['properties']['lai']\n",
    "            aot = feature['properties']['aot'] #drop AOT if you aren't worried about smoke/pollution\n",
    "            data.append((date, clear_sky_percentage, ndvi, lai, aot))\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Date', 'Clear_Sky_Percentage', 'NDVI', 'LAI', 'AOT'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])  # Ensure 'Date' column is of datetime type\n",
    "    \n",
    "    # Save the DataFrame as a CSV file in the same folder as the shapefile\n",
    "    csv_path = os.path.join(os.path.dirname(shapefile_path), f'{site_name}_{year}_data.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Find the closest date to the survey end date with different clear sky thresholds - you can drop the thresholds if your area of interest is less cloudy\n",
    "    end_date = survey_ranges[year][1]\n",
    "    closest_dates = {}\n",
    "    for threshold in [80, 90, 95, 99]:\n",
    "        df_filtered = df[df['Clear_Sky_Percentage'] >= threshold]\n",
    "        if not df_filtered.empty:\n",
    "            closest_date = df_filtered.iloc[(df_filtered['Date'] - end_date).abs().argsort()[:1]]['Date'].values[0]\n",
    "            closest_dates[threshold] = closest_date\n",
    "        else:\n",
    "            closest_dates[threshold] = None\n",
    "    \n",
    "    print(f\"Year {year} for site {site_name}: Closest dates to end of survey\")\n",
    "    for threshold, date in closest_dates.items():\n",
    "        print(f\"{threshold}% clear sky: {date}\")\n",
    "    \n",
    "    return df, closest_dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c55abcd-c762-408c-8dbd-332c37198216",
   "metadata": {},
   "source": [
    "\n",
    "This section runs the functions defined above to processes satellite imagery data for specified sites and years to calculate clear sky percentages, NDVI, LAI, and AOT indices. It identifies and records the closest dates with different clear sky thresholds to the end of survey periods, saving these dates in a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e8870-302e-4776-b7d2-b1b52c0ffb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2023]  # Adjust the years as needed\n",
    "\n",
    "# Store data frames and closest dates for each year and site\n",
    "all_data_frames = {}\n",
    "closest_dates_all_sites = []\n",
    "\n",
    "# Process by polygon (first \"for\") - Pull indicies (second \"for\") - Pull closest dates (third \"for\") \n",
    "for i, (polygon, site_name) in enumerate(zip(polygons, site_names)):\n",
    "    print(f\"Processing polygon {i+1}/{len(polygons)} for site {site_name}\")\n",
    "    \n",
    "    try:\n",
    "        for year in years:\n",
    "            df, closest_dates = process_year_data(year, polygon, site_name)\n",
    "            all_data_frames[(site_name, year)] = df\n",
    "            for threshold, date in closest_dates.items():\n",
    "                closest_dates_all_sites.append({\n",
    "                    'Site': site_name,\n",
    "                    'Year': year,\n",
    "                    'Threshold': threshold,\n",
    "                    'Date': date\n",
    "                })\n",
    "    \n",
    "    except ee.ee_exception.EEException as e:\n",
    "        print(f\"Error processing polygon {i+1} for site {site_name}: {e}\")\n",
    "\n",
    "# Save the closest dates to a separate CSV file from the site/year indicies\n",
    "closest_dates_df = pd.DataFrame(closest_dates_all_sites)\n",
    "closest_dates_csv_path = os.path.join(os.path.dirname(shapefile_path), 'closest_dates_to_survey_end.csv')\n",
    "closest_dates_df.to_csv(closest_dates_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f28f9b9-0b04-4b5d-b396-27a8b60bc5ad",
   "metadata": {},
   "source": [
    "This code generates scatter plots of the NDVI and LAI indices, highlighting the closest date with over 99% clear sky pixels, and saves these plots as images in the working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d494ae9-2019-4764-b5aa-99c259f6e062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_indices(df, site_name, year, index, survey_start, survey_end, closest_date_99):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    df = df[df['Clear_Sky_Percentage'] >= 90]\n",
    "    \n",
    "    survey_period = (df['Date'] >= survey_start) & (df['Date'] <= survey_end)\n",
    "    x = pd.to_datetime(df['Date'])\n",
    "    y = df[index]\n",
    "    \n",
    "    plt.scatter(x[~survey_period], y[~survey_period], label=f'{site_name} {index}', alpha=0.6, color='cornflowerblue')\n",
    "    \n",
    "    non_survey_data = df[~survey_period]\n",
    "    if not non_survey_data.empty:\n",
    "        non_survey_data = non_survey_data.sort_values('Date')\n",
    "        x = non_survey_data['Date'].map(datetime.toordinal)\n",
    "        y = non_survey_data[index]\n",
    "        spline = interpolate.UnivariateSpline(x, y, s=0.8) # Increase s value for more smoothing\n",
    "        xs = np.linspace(x.min(), x.max(), 500)\n",
    "        plt.plot([datetime.fromordinal(int(x)) for x in xs], spline(xs), label='Spline Fit', color='green')\n",
    "    \n",
    "    plt.axvspan(survey_start, survey_end, color='grey', alpha=0.3, label='Survey Period')\n",
    "    \n",
    "    # Highlight the closest date with >99% clear sky pixels - For downloading full image for SNAP Biophysical Properties analysis\n",
    "    if closest_date_99:\n",
    "        plt.scatter(pd.to_datetime(closest_date_99), df[df['Date'] == pd.to_datetime(closest_date_99)][index], color='yellow', label='Closest Date >99% Clear Sky', zorder=5)\n",
    "\n",
    "    plt.title(f'{index} by Date for Site: {site_name} ({year})')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(index)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    months = pd.date_range(start=f'{year}-04-01', end=f'{year}-10-31', freq='MS').strftime('%b')\n",
    "    plt.xticks(pd.date_range(start=f'{year}-04-01', end=f'{year}-10-31', freq='MS'), months)\n",
    "    \n",
    "    plot_path = os.path.join(os.path.dirname(shapefile_path), f'{site_name}_{year}_{index}.png')\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "# Generate scatterplots for each site and year\n",
    "for (site_name, year), df in all_data_frames.items():\n",
    "    survey_start, survey_end = survey_ranges[year]\n",
    "    closest_date_99 = next((entry['Date'] for entry in closest_dates_all_sites if entry['Site'] == site_name and entry['Year'] == year and entry['Threshold'] == 99), None)\n",
    "    plot_indices(df, site_name, year, 'NDVI', survey_start, survey_end, closest_date_99)\n",
    "    plot_indices(df, site_name, year, 'LAI', survey_start, survey_end, closest_date_99)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
